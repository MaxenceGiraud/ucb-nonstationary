In this report we sum up the work of Garivier et al. \cite{garivier2008upperconfidence} and try to extend their work to new possibilities. This paper is about finding an algorithm for the non-stationary bandit problem. The authors study two algorithms, both based on \textit{Upper-Confidence Bound}(UCB) policies. The first, already existing algorithm is \textit{Discounted-UCB}(D-UCB), and they propose another one, \textit{Sliding-Window UCB}(SW-UCB). We implemented both policies and try to compare to two new variants we came up with of \textit{Sliding-Window UCB}(SW-UCB).